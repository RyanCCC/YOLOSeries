{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original model without weight cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.5104 - accuracy: 0.8547 - val_loss: 0.1140 - val_accuracy: 0.9700\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1275 - accuracy: 0.9638 - val_loss: 0.0933 - val_accuracy: 0.9750\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0871 - accuracy: 0.9755 - val_loss: 0.0749 - val_accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0722 - accuracy: 0.9788 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0626 - accuracy: 0.9812 - val_loss: 0.0649 - val_accuracy: 0.9825\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0541 - accuracy: 0.9840 - val_loss: 0.0612 - val_accuracy: 0.9830\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0482 - accuracy: 0.9861 - val_loss: 0.0654 - val_accuracy: 0.9822\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0428 - accuracy: 0.9877 - val_loss: 0.0615 - val_accuracy: 0.9840\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0406 - accuracy: 0.9877 - val_loss: 0.0619 - val_accuracy: 0.9852\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0364 - accuracy: 0.9895 - val_loss: 0.0679 - val_accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28e50b66808>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mnist model\n",
    "mnisi = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnisi.load_data()\n",
    "# 标准化\n",
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0\n",
    "# 定义模型\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28,28)),\n",
    "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "# 训练模型\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9819999933242798\n"
     ]
    }
   ],
   "source": [
    "# 评估并保存\n",
    "_, baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "# save model\n",
    "model_without_cluster = './model/original_without_cluster.h5'\n",
    "tf.keras.models.save_model(model, './model/original_without_cluster.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cluster_reshape_1 (ClusterWe (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "cluster_conv2d_1 (ClusterWei (None, 26, 26, 12)        244       \n",
      "_________________________________________________________________\n",
      "cluster_max_pooling2d_1 (Clu (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "cluster_flatten_1 (ClusterWe (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "cluster_dense_1 (ClusterWeig (None, 10)                40586     \n",
      "=================================================================\n",
      "Total params: 40,830\n",
      "Trainable params: 20,442\n",
      "Non-trainable params: 20,388\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 16,\n",
    "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 6s 55ms/step - loss: 0.0543 - accuracy: 0.9817 - val_loss: 0.0748 - val_accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28e532e8a88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune weight-cluster model\n",
    "clustered_model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=500,\n",
    "  epochs=1,\n",
    "  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9803000092506409\n",
      "Clustered test accuracy: 0.9776999950408936\n"
     ]
    }
   ],
   "source": [
    "_, clustered_model_accuracy = clustered_model.evaluate(\n",
    "  test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Clustered test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving clustered model to:  ./model/original_with_cluster.h5\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "clustered_keras_file = './model/original_with_cluster.h5'\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "tf.keras.models.save_model(final_model, clustered_keras_file, \n",
    "                           include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\wendy\\AppData\\Local\\Temp\\tmp6hi33c5n\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\wendy\\AppData\\Local\\Temp\\tmp6hi33c5n\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustered TFLite model to: ./model/clustered_mnist.tflite\n"
     ]
    }
   ],
   "source": [
    "# 保存成可压缩的模型\n",
    "clustered_tflite_file = './model/clustered_mnist.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "tflite_clustered_model = converter.convert()\n",
    "with open(clustered_tflite_file, 'wb') as f:\n",
    "  f.write(tflite_clustered_model)\n",
    "print('Saved clustered TFLite model to:', clustered_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "def get_gzipped_model_size(file):\n",
    "  # It returns the size of the gzipped model in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\wendy\\AppData\\Local\\Temp\\tmp5mmrdm21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\wendy\\AppData\\Local\\Temp\\tmp5mmrdm21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and clustered TFLite model to: C:\\Users\\wendy\\AppData\\Local\\Temp\\tmp14fjakoh.tflite\n",
      "Size of gzipped baseline Keras model: 1760.00 bytes\n",
      "Size of gzipped clustered and quantized TFlite model: 9828.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "_, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
    "  f.write(tflite_quant_model)\n",
    "\n",
    "print('Saved quantized and clustered TFLite model to:', quantized_and_clustered_tflite_file)\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(model_without_cluster)))\n",
    "print(\"Size of gzipped clustered and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看tflite的准确性\n",
    "def eval_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CreateWrapperFromBuffer(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: bytes, arg1: List[str]) -> tflite::interpreter_wrapper::InterpreterWrapper\n    2. (arg0: bytes, arg1: List[str], arg2: List[Callable[[int], None]]) -> tflite::interpreter_wrapper::InterpreterWrapper\n\nInvoked with: './model/clustered_mnist.tflite', [], []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_124888\\1558724835.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclustered_tflite_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, model_content, experimental_delegates, num_threads)\u001b[0m\n\u001b[0;32m    222\u001b[0m           _interpreter_wrapper.CreateWrapperFromBuffer(\n\u001b[0;32m    223\u001b[0m               \u001b[0mmodel_content\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_op_registerers_by_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m               custom_op_registerers_by_func))\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_content\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`model_path` or `model_content` must be specified.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: CreateWrapperFromBuffer(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: bytes, arg1: List[str]) -> tflite::interpreter_wrapper::InterpreterWrapper\n    2. (arg0: bytes, arg1: List[str], arg2: List[Callable[[int], None]]) -> tflite::interpreter_wrapper::InterpreterWrapper\n\nInvoked with: './model/clustered_mnist.tflite', [], []"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = eval_model(interpreter)\n",
    "\n",
    "print('Clustered and quantized TFLite test_accuracy:', test_accuracy)\n",
    "print('Clustered TF test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c7c5c079346ce5c32a13af6f9c43b51d7027f08e22779c2ee30895e060b5a2d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
