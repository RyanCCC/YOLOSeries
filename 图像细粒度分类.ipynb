{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像细粒度分类\n",
    "\n",
    "Inception、Xception、NASNetLarge、InceptionRes in Tensorflow2\n",
    "\n",
    "Kaggle Competition:Dog Breed Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout, Lambda, Input, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'D:\\Code\\Exercise\\dog-breed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集处理\n",
    "\n",
    "数据主要结构是训练集图像放在训练集文件夹里面，标签以csv格式的数据记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id             breed\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n",
      "                                      id               breed\n",
      "count                              10222               10222\n",
      "unique                             10222                 120\n",
      "top     56d91388512400bf079a9663dd0b5ad5  scottish_deerhound\n",
      "freq                                   1                 126\n"
     ]
    }
   ],
   "source": [
    "# 读取标签\n",
    "label_path = os.path.join(base_path, 'labels.csv')\n",
    "labels = pd.read_csv(label_path)\n",
    "print(labels.head())\n",
    "print(labels.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique breed 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'affenpinscher': 0,\n",
       " 'afghan_hound': 1,\n",
       " 'african_hunting_dog': 2,\n",
       " 'airedale': 3,\n",
       " 'american_staffordshire_terrier': 4,\n",
       " 'appenzeller': 5,\n",
       " 'australian_terrier': 6,\n",
       " 'basenji': 7,\n",
       " 'basset': 8,\n",
       " 'beagle': 9,\n",
       " 'bedlington_terrier': 10,\n",
       " 'bernese_mountain_dog': 11,\n",
       " 'black-and-tan_coonhound': 12,\n",
       " 'blenheim_spaniel': 13,\n",
       " 'bloodhound': 14,\n",
       " 'bluetick': 15,\n",
       " 'border_collie': 16,\n",
       " 'border_terrier': 17,\n",
       " 'borzoi': 18,\n",
       " 'boston_bull': 19,\n",
       " 'bouvier_des_flandres': 20,\n",
       " 'boxer': 21,\n",
       " 'brabancon_griffon': 22,\n",
       " 'briard': 23,\n",
       " 'brittany_spaniel': 24,\n",
       " 'bull_mastiff': 25,\n",
       " 'cairn': 26,\n",
       " 'cardigan': 27,\n",
       " 'chesapeake_bay_retriever': 28,\n",
       " 'chihuahua': 29,\n",
       " 'chow': 30,\n",
       " 'clumber': 31,\n",
       " 'cocker_spaniel': 32,\n",
       " 'collie': 33,\n",
       " 'curly-coated_retriever': 34,\n",
       " 'dandie_dinmont': 35,\n",
       " 'dhole': 36,\n",
       " 'dingo': 37,\n",
       " 'doberman': 38,\n",
       " 'english_foxhound': 39,\n",
       " 'english_setter': 40,\n",
       " 'english_springer': 41,\n",
       " 'entlebucher': 42,\n",
       " 'eskimo_dog': 43,\n",
       " 'flat-coated_retriever': 44,\n",
       " 'french_bulldog': 45,\n",
       " 'german_shepherd': 46,\n",
       " 'german_short-haired_pointer': 47,\n",
       " 'giant_schnauzer': 48,\n",
       " 'golden_retriever': 49,\n",
       " 'gordon_setter': 50,\n",
       " 'great_dane': 51,\n",
       " 'great_pyrenees': 52,\n",
       " 'greater_swiss_mountain_dog': 53,\n",
       " 'groenendael': 54,\n",
       " 'ibizan_hound': 55,\n",
       " 'irish_setter': 56,\n",
       " 'irish_terrier': 57,\n",
       " 'irish_water_spaniel': 58,\n",
       " 'irish_wolfhound': 59,\n",
       " 'italian_greyhound': 60,\n",
       " 'japanese_spaniel': 61,\n",
       " 'keeshond': 62,\n",
       " 'kelpie': 63,\n",
       " 'kerry_blue_terrier': 64,\n",
       " 'komondor': 65,\n",
       " 'kuvasz': 66,\n",
       " 'labrador_retriever': 67,\n",
       " 'lakeland_terrier': 68,\n",
       " 'leonberg': 69,\n",
       " 'lhasa': 70,\n",
       " 'malamute': 71,\n",
       " 'malinois': 72,\n",
       " 'maltese_dog': 73,\n",
       " 'mexican_hairless': 74,\n",
       " 'miniature_pinscher': 75,\n",
       " 'miniature_poodle': 76,\n",
       " 'miniature_schnauzer': 77,\n",
       " 'newfoundland': 78,\n",
       " 'norfolk_terrier': 79,\n",
       " 'norwegian_elkhound': 80,\n",
       " 'norwich_terrier': 81,\n",
       " 'old_english_sheepdog': 82,\n",
       " 'otterhound': 83,\n",
       " 'papillon': 84,\n",
       " 'pekinese': 85,\n",
       " 'pembroke': 86,\n",
       " 'pomeranian': 87,\n",
       " 'pug': 88,\n",
       " 'redbone': 89,\n",
       " 'rhodesian_ridgeback': 90,\n",
       " 'rottweiler': 91,\n",
       " 'saint_bernard': 92,\n",
       " 'saluki': 93,\n",
       " 'samoyed': 94,\n",
       " 'schipperke': 95,\n",
       " 'scotch_terrier': 96,\n",
       " 'scottish_deerhound': 97,\n",
       " 'sealyham_terrier': 98,\n",
       " 'shetland_sheepdog': 99,\n",
       " 'shih-tzu': 100,\n",
       " 'siberian_husky': 101,\n",
       " 'silky_terrier': 102,\n",
       " 'soft-coated_wheaten_terrier': 103,\n",
       " 'staffordshire_bullterrier': 104,\n",
       " 'standard_poodle': 105,\n",
       " 'standard_schnauzer': 106,\n",
       " 'sussex_spaniel': 107,\n",
       " 'tibetan_mastiff': 108,\n",
       " 'tibetan_terrier': 109,\n",
       " 'toy_poodle': 110,\n",
       " 'toy_terrier': 111,\n",
       " 'vizsla': 112,\n",
       " 'walker_hound': 113,\n",
       " 'weimaraner': 114,\n",
       " 'welsh_springer_spaniel': 115,\n",
       " 'west_highland_white_terrier': 116,\n",
       " 'whippet': 117,\n",
       " 'wire-haired_fox_terrier': 118,\n",
       " 'yorkshire_terrier': 119}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据的格式\n",
    "#Create list of alphabetically sorted labels.\n",
    "classes = sorted(list(set(labels['breed'])))\n",
    "n_classes = len(classes)\n",
    "print('Total unique breed {}'.format(n_classes))\n",
    "\n",
    "#Map each label string to an integer label.\n",
    "class_to_num = dict(zip(classes, range(n_classes)))\n",
    "class_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置成331的原因是NASNetLarge默认的输入shape大小是(331, 331, 3)\n",
    "img_size = (331, 331, 3)\n",
    "\n",
    "def images_to_array(directory, label_dataframe, target_size = img_size):\n",
    "    image_labels = label_dataframe['breed']\n",
    "    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8)\n",
    "    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n",
    "    for ix, image_name in enumerate(label_dataframe['id'].values):\n",
    "        img_dir = os.path.join(directory, image_name+'.jpg')\n",
    "        img = load_img(img_dir, target_size=target_size)\n",
    "        images[ix]=img\n",
    "        del img\n",
    "\n",
    "        dog_breed = image_labels[ix]\n",
    "        y[ix] = class_to_num[dog_breed]\n",
    "    y = to_categorical(y)\n",
    "    return images, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "t = time.time()\n",
    "image_path = os.path.join(base_path, 'train')\n",
    "X,y = images_to_array(image_path, labels[:])\n",
    "print('runtime in seconds: {}'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示数据\n",
    "import matplotlib.pyplot as plt\n",
    "n=25\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(5, 5, i+1)\n",
    "    plt.title(classes[np.where(y[i] ==1)[0][0]])\n",
    "    plt.imshow(X[i].astype('int32')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型\n",
    "建立Inception、Xception、NASNetLarge, InceptionRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature(model_name, model_preprocessor, input_size, data):\n",
    "    input_layer = Input(img_size)\n",
    "    preprocessor = Lambda(model_preprocessor)(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False, input_shape = input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs=input_layer, outputs=avg)\n",
    "    # Extract feature\n",
    "    feature_maps = feature_extractor.predict(data, verbose=1)\n",
    "    print('Feature maps shape:', feature_maps.shape)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract featurs using InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "inception_preprocessor = preprocess_input\n",
    "inception_features = get_feature(InceptionV3, inception_preprocessor, img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using Xception \n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "xception_preprocessor = preprocess_input\n",
    "xception_features = get_feature(Xception,\n",
    "                                 xception_preprocessor,\n",
    "                                 img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using InceptionResNetV2 \n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "inc_resnet_preprocessor = preprocess_input\n",
    "inc_resnet_features = get_feature(InceptionResNetV2,\n",
    "                                   inc_resnet_preprocessor,\n",
    "                                   img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using NASNetLarge \n",
    "from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "nasnet_preprocessor = preprocess_input\n",
    "nasnet_features = get_feature(NASNetLarge,\n",
    "                               nasnet_preprocessor,\n",
    "                               img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size= 128\n",
    "epochs=50\n",
    "learn_rate=.001\n",
    "sgd=tf.keras.optimizers.SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "adam= tf.keras.optimizers.Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5,verbose = 1)\n",
    "\n",
    "#Prepare call backs\n",
    "EarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating final featuremap by combining all extracted features\n",
    "\n",
    "final_features = np.concatenate([inception_features,\n",
    "                                 xception_features,\n",
    "                                #  nasnet_features,\n",
    "                                 inc_resnet_features], axis=-1) #axis=-1 to concatinate horizontally\n",
    "\n",
    "print('Final feature maps shape', final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Deep net\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Dense(1028,input_shape=(final_features.shape[1],)))\n",
    "model.add(Dropout(0.7,input_shape=(final_features.shape[1],)))\n",
    "model.add(Dense(n_classes,activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model. \n",
    "history = model.fit(final_features, y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[lrr,EarlyStop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g = load_img('./dog-breed/train/0a0c223352985ec154fd604d7ddceabd.jpg',target_size = img_size)\n",
    "img_g = np.expand_dims(img_g, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Predict test labels given test data features.\n",
    "test_features = extact_features(img_g)\n",
    "predg = model.predict(test_features)\n",
    "print(f\"Predicted label: {classes[np.argmax(predg[0])]}\")\n",
    "print(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c7c5c079346ce5c32a13af6f9c43b51d7027f08e22779c2ee30895e060b5a2d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
