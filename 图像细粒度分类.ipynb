{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像细粒度分类\n",
    "\n",
    "Inception、Xception、NASNetLarge、InceptionRes in Tensorflow2\n",
    "\n",
    "Kaggle Competition:Dog Breed Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout, Lambda, Input, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集处理\n",
    "\n",
    "数据主要结构是训练集图像放在训练集文件夹里面，标签以csv格式的数据记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取标签\n",
    "labels = pd.read_csv('./dog-breed/labels.csv')\n",
    "print(labels.head())\n",
    "print(labels.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据的格式\n",
    "#Create list of alphabetically sorted labels.\n",
    "classes = sorted(list(set(labels['breed'])))\n",
    "n_classes = len(classes)\n",
    "print('Total unique breed {}'.format(n_classes))\n",
    "\n",
    "#Map each label string to an integer label.\n",
    "class_to_num = dict(zip(classes, range(n_classes)))\n",
    "class_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置成331的原因是NASNetLarge默认的输入shape大小是(331, 331, 3)\n",
    "img_size = (331, 331, 3)\n",
    "\n",
    "def images_to_array(directory, label_dataframe, target_size = img_size):\n",
    "    image_labels = label_dataframe['breed']\n",
    "    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8)\n",
    "    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n",
    "    for ix, image_name in enumerate(label_dataframe['id'].values):\n",
    "        img_dir = os.path.join(directory, image_name+'.jpg')\n",
    "        img = load_img(img_dir, target_size=target_size)\n",
    "        images[ix]=img\n",
    "        del img\n",
    "\n",
    "        dog_breed = image_labels[ix]\n",
    "        y[ix] = class_to_num[dog_breed]\n",
    "    y = to_categorical(y)\n",
    "    return images, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "t = time.time()\n",
    "X,y = images_to_array('./dog-breed/train', labels[:])\n",
    "print('runtime in seconds: {}'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示数据\n",
    "import matplotlib.pyplot as plt\n",
    "n=25\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(5, 5, i+1)\n",
    "    plt.title(classes[np.where(y[i] ==1)[0][0]])\n",
    "    plt.imshow(X[i].astype('int32')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型\n",
    "建立Inception、Xception、NASNetLarge, InceptionRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature(model_name, model_preprocessor, input_size, data):\n",
    "    input_layer = Input(img_size)\n",
    "    preprocessor = Lambda(model_preprocessor)(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False, input_shape = input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs=input_layer, outputs=avg)\n",
    "    # Extract feature\n",
    "    feature_maps = feature_extractor.predict(data, verbose=1)\n",
    "    print('Feature maps shape:', feature_maps.shape)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract featurs using InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "inception_preprocessor = preprocess_input\n",
    "inception_features = get_feature(InceptionV3, inception_preprocessor, img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using Xception \n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "xception_preprocessor = preprocess_input\n",
    "xception_features = get_feature(Xception,\n",
    "                                 xception_preprocessor,\n",
    "                                 img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using InceptionResNetV2 \n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "inc_resnet_preprocessor = preprocess_input\n",
    "inc_resnet_features = get_feature(InceptionResNetV2,\n",
    "                                   inc_resnet_preprocessor,\n",
    "                                   img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using NASNetLarge \n",
    "from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "nasnet_preprocessor = preprocess_input\n",
    "nasnet_features = get_feature(NASNetLarge,\n",
    "                               nasnet_preprocessor,\n",
    "                               img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size= 128\n",
    "epochs=50\n",
    "learn_rate=.001\n",
    "sgd=tf.keras.optimizers.SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "adam= tf.keras.optimizers.Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5,verbose = 1)\n",
    "\n",
    "#Prepare call backs\n",
    "EarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating final featuremap by combining all extracted features\n",
    "\n",
    "final_features = np.concatenate([inception_features,\n",
    "                                 xception_features,\n",
    "                                #  nasnet_features,\n",
    "                                 inc_resnet_features], axis=-1) #axis=-1 to concatinate horizontally\n",
    "\n",
    "print('Final feature maps shape', final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Deep net\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Dense(1028,input_shape=(final_features.shape[1],)))\n",
    "model.add(Dropout(0.7,input_shape=(final_features.shape[1],)))\n",
    "model.add(Dense(n_classes,activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model. \n",
    "history = model.fit(final_features, y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[lrr,EarlyStop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g = load_img('./dog-breed/train/0a0c223352985ec154fd604d7ddceabd.jpg',target_size = img_size)\n",
    "img_g = np.expand_dims(img_g, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Predict test labels given test data features.\n",
    "test_features = extact_features(img_g)\n",
    "predg = model.predict(test_features)\n",
    "print(f\"Predicted label: {classes[np.argmax(predg[0])]}\")\n",
    "print(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c7c5c079346ce5c32a13af6f9c43b51d7027f08e22779c2ee30895e060b5a2d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
